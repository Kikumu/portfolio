<!DOCTYPE HTML>
<html>
	<head>
		<title>Deep Reinforcement Learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="projects_assets/css/main.css" />
		<noscript><link rel="stylesheet" href="projects_assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html#portfolio" class="logo"><strong>Back</strong></a>
					</header>
				<!-- Main -->
					<div id="main" class="alt">
						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h1>Deep Reinforcement Learning.</h1>
									</header>
									<span class="image main"><img height = "500"src="images/DRL.png" alt="" /></span>
									<h2>Project overview and inspiration.</h2>
									<p>Adding onto the previous project on reinforcement learning, the main goal of this project was to utilize aspects of both reinforcement learning and deep learning to solve a game environment created by a good friend of mine. The name of the game is called Lets Break Suma! which is an adaptation of Atari's Blockbreaker Game. The link to the game can be found <a href="https://github.com/Amreiz/LetsBreakSuma">here.</a></p>
									<h2>How it operates.</h2>
									<p>The agent operates using the same principle of reinforcement learning as used in my previous project with a twist. That being, adding a neural network which helps the agent in making better desicions(actions) depending on the environment state(images captured on screen). I first started by implementing a fully connected layer to the reinforcement learning algorithm which obtains frames from the game. The output of the fully connected layer is 10 different mouse positions which moves the paddle to different sections of the screen so that the agent can hit the ball. This was done using Pythons pyautogui library in regard to moving mouse positions. Rewards are assigned to the agent depending on the number of blocks hit per episode. An episode is a period of time in which the game runs without the agent missing to hit the ball on the paddle(if the agent fails to hit the ball with the paddle, the game ends and starts a fresh one), or the agent cleared the level by hitting all the blocks.</p>
									<h2>How to install.</h2>
									<p>Further information on how to install and run the game can be found <a href="https://github.com/Kikumu/Combining-model-free-reinforcement-learning-with-Deep-learning">here.</a> The video below shows the AI in action! 
										<iframe width="560" height="315" src="https://www.youtube.com/embed/TJhAUeAj1zg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
									</p>
									<h2>Future work.</h2>
									<p>Future project involves using a much more complex game environment (and algorithm) which utilizes aspects of deep reinforcement learning. I plan to train an agent to play the Super Mario Videogame.</p>
								</div>
							</section>
					</div>
				<!-- Footer -->
			</div>

		<!-- Scripts -->
			<script src="projects_assets/js/jquery.min.js"></script>
			<script src="projects_assets/js/jquery.scrolly.min.js"></script>
			<script src="projects_assets/js/jquery.scrollex.min.js"></script>
			<script src="projects_assets/js/browser.min.js"></script>
			<script src="projects_assets/js/breakpoints.min.js"></script>
			<script src="projects_assets/js/util.js"></script>
			<script src="projects_assets/js/main.js"></script>

	</body>
</html>